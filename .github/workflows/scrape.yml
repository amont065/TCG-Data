name: Scheduled Scrape

on:
  schedule:
    - cron: '0 * * * *'   # every hour on the hour (UTC)
  workflow_dispatch:      # lets you "Run workflow" manually

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y firefox xvfb

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager requests
          # If you have a requirements.txt file, uncomment the next line
          # pip install -r requirements.txt

      - name: Install Geckodriver
        run: |
          # Get latest geckodriver version
          GECKODRIVER_VERSION=$(curl -s https://api.github.com/repos/mozilla/geckodriver/releases/latest | grep -Po '"tag_name": "\K.*?(?=")')
          # Download and install geckodriver
          wget -O geckodriver.tar.gz "https://github.com/mozilla/geckodriver/releases/download/${GECKODRIVER_VERSION}/geckodriver-${GECKODRIVER_VERSION}-linux64.tar.gz"
          tar -xzf geckodriver.tar.gz
          sudo mv geckodriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/geckodriver
          # Verify installation
          geckodriver --version

      - name: Setup Firefox in headless mode
        run: |
          export DISPLAY=:99
          Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &

      - name: Run scraper
        run: |
          export DISPLAY=:99
          python scraper.py
        env:
          HEADLESS: true

      - name: Check scraper output and CSV
        run: |
          echo "=== Current directory contents ==="
          ls -la
          echo ""
          echo "=== Looking for CSV files ==="
          find . -name "*.csv" -type f
          echo ""
          if [ -f "_Cards_Main.csv" ]; then
            echo "✅ CSV file found!"
            echo "File size: $(stat -c%s "_Cards_Main.csv") bytes"
            echo "Number of lines: $(wc -l < "_Cards_Main.csv")"
            echo "First few lines:"
            head -5 "_Cards_Main.csv"
          else
            echo "❌ CSV file not found"
            echo "Creating empty CSV file to prevent upload failure"
            echo "No data scraped at $(date)" > "_Cards_Main.csv"
          fi

      - name: Upload CSV
        uses: actions/upload-artifact@v4
        with:
          name: cards-data-${{ github.run_number }}
          path: _Cards_Main.csv
          if-no-files-found: warn
